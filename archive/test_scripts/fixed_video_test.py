#!/usr/bin/env python3
"""
Fixed Video Testing for Rodent Detection with Proper YOLO Decoding
"""

import cv2
import numpy as np
import onnxruntime as ort
import json
from pathlib import Path
from datetime import datetime

class FixedRodentTester:
    def __init__(self):
        self.model_path = Path("models/best.onnx")
        self.test_videos_dir = Path("/Users/zakariamasoodgosign/Documents/zakaria/Freelance/RAT_Project/Test_videos")
        self.output_dir = Path("test_results") / f"fixed_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Test with very low thresholds to catch any detection
        self.conf_threshold = 0.01  # Very low to catch everything
        self.iou_threshold = 0.45
        
        # Class names for rodent detection
        self.class_names = ['norway_rat', 'roof_rat']
        
        # Load model
        print("Loading ONNX model...")
        self.session = ort.InferenceSession(str(self.model_path))
        self.input_name = self.session.get_inputs()[0].name
        print("‚úÖ Model loaded successfully")
        
    def preprocess_frame(self, frame):
        """Preprocess frame for model input"""
        # Resize and convert
        resized = cv2.resize(frame, (640, 640))
        rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
        
        # Normalize to [0,1]
        normalized = rgb.astype(np.float32) / 255.0
        
        # Transpose to CHW format
        transposed = np.transpose(normalized, (2, 0, 1))
        
        # Add batch dimension
        batch = np.expand_dims(transposed, axis=0)
        
        return batch
    
    def decode_output(self, output):
        """Properly decode YOLO output format"""
        # Output shape: [1, 6, 8400] 
        # 6 channels: [x, y, w, h, obj_conf, num_classes]
        
        output = output[0]  # Shape: [1, 6, 8400]
        
        # Extract components
        boxes = output[0, :4, :]  # x, y, w, h (shape: 4, 8400)
        obj_confs = output[0, 4, :]  # objectness scores (shape: 8400)
        class_probs = output[0, 5:, :]  # class probabilities (shape: 1, 8400) for binary classification
        
        # Find predictions with high objectness
        valid_indices = np.where(obj_confs > self.conf_threshold)[0]
        
        detections = []
        
        for idx in valid_indices:
            obj_conf = obj_confs[idx]
            
            # For binary classification (rat vs no rat)
            if class_probs.shape[0] == 1:
                # Single class probability
                class_prob = class_probs[0, idx]
                confidence = obj_conf * class_prob
                class_id = 0 if class_prob > 0.5 else 1
            else:
                # Multi-class
                class_probs_idx = class_probs[:, idx]
                class_id = np.argmax(class_probs_idx)
                class_prob = class_probs_idx[class_id]
                confidence = obj_conf * class_prob
            
            if confidence > self.conf_threshold:
                # Get box coordinates
                x, y, w, h = boxes[:, idx]
                
                # Convert from center format to corner format
                x1 = int((x - w/2) * 640)
                y1 = int((y - h/2) * 640)
                x2 = int((x + w/2) * 640)
                y2 = int((y + h/2) * 640)
                
                # Clamp to image boundaries
                x1 = max(0, min(x1, 640))
                y1 = max(0, min(y1, 640))
                x2 = max(0, min(x2, 640))
                y2 = max(0, min(y2, 640))
                
                if x2 > x1 and y2 > y1:
                    class_name = self.class_names[class_id] if class_id < len(self.class_names) else f"class_{class_id}"
                    
                    detections.append({
                        'class': class_name,
                        'confidence': float(confidence),
                        'obj_conf': float(obj_conf),
                        'bbox': [x1, y1, x2, y2]
                    })
        
        # Apply NMS
        if len(detections) > 1:
            detections = self.apply_nms(detections)
        
        return detections
    
    def apply_nms(self, detections):
        """Apply Non-Maximum Suppression"""
        if len(detections) == 0:
            return detections
        
        # Sort by confidence
        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)
        
        keep = []
        while detections:
            current = detections.pop(0)
            keep.append(current)
            
            # Remove overlapping boxes
            detections = [d for d in detections 
                         if self.calculate_iou(current['bbox'], d['bbox']) < self.iou_threshold]
        
        return keep
    
    def calculate_iou(self, box1, box2):
        """Calculate Intersection over Union"""
        x1_min, y1_min, x1_max, y1_max = box1
        x2_min, y2_min, x2_max, y2_max = box2
        
        # Intersection
        inter_xmin = max(x1_min, x2_min)
        inter_ymin = max(y1_min, y2_min)
        inter_xmax = min(x1_max, x2_max)
        inter_ymax = min(y1_max, y2_max)
        
        if inter_xmax <= inter_xmin or inter_ymax <= inter_ymin:
            return 0.0
        
        inter_area = (inter_xmax - inter_xmin) * (inter_ymax - inter_ymin)
        
        # Union
        box1_area = (x1_max - x1_min) * (y1_max - y1_min)
        box2_area = (x2_max - x2_min) * (y2_max - y2_min)
        union_area = box1_area + box2_area - inter_area
        
        return inter_area / union_area
    
    def draw_detections(self, frame, detections):
        """Draw bounding boxes on frame"""
        annotated = frame.copy()
        h, w = frame.shape[:2]
        
        for det in detections:
            # Scale bbox from 640x640 to original size
            x1, y1, x2, y2 = det['bbox']
            x1 = int(x1 * w / 640)
            y1 = int(y1 * h / 640)
            x2 = int(x2 * w / 640)
            y2 = int(y2 * h / 640)
            
            # Choose color based on confidence
            conf = det['confidence']
            if conf > 0.5:
                color = (0, 255, 0)  # Green
            elif conf > 0.25:
                color = (0, 165, 255)  # Orange
            else:
                color = (255, 0, 0)  # Blue for low confidence
            
            # Draw box
            cv2.rectangle(annotated, (x1, y1), (x2, y2), color, 2)
            
            # Draw label
            label = f"{det['class']}: {conf:.2%}"
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
            
            cv2.rectangle(annotated, 
                         (x1, y1 - label_size[1] - 4),
                         (x1 + label_size[0], y1),
                         color, -1)
            
            cv2.putText(annotated, label,
                       (x1, y1 - 2),
                       cv2.FONT_HERSHEY_SIMPLEX,
                       0.5, (255, 255, 255), 2)
        
        return annotated
    
    def process_video(self, video_path):
        """Process a single video"""
        video_name = video_path.stem
        print(f"\nüìπ Processing: {video_path.name}")
        print("-" * 40)
        
        cap = cv2.VideoCapture(str(video_path))
        if not cap.isOpened():
            print(f"‚ùå Failed to open video")
            return None
        
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        print(f"   Resolution: {width}x{height}")
        print(f"   FPS: {fps:.1f}")
        print(f"   Total frames: {total_frames}")
        
        # Sample frames
        sample_interval = max(1, int(fps))  # Sample 1 frame per second
        
        results = {
            'video': video_path.name,
            'total_frames': total_frames,
            'frames_processed': 0,
            'detections': [],
            'max_confidence': 0,
            'total_detections': 0
        }
        
        frame_idx = 0
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            if frame_idx % sample_interval == 0:
                # Preprocess
                input_tensor = self.preprocess_frame(frame)
                
                # Run inference
                outputs = self.session.run(None, {self.input_name: input_tensor})
                
                # Decode output
                detections = self.decode_output(outputs)
                
                results['frames_processed'] += 1
                
                if detections:
                    results['total_detections'] += len(detections)
                    
                    # Find max confidence
                    max_conf = max(d['confidence'] for d in detections)
                    if max_conf > results['max_confidence']:
                        results['max_confidence'] = max_conf
                    
                    # Log detection
                    print(f"   Frame {frame_idx}: {len(detections)} detection(s)")
                    for det in detections:
                        print(f"      ‚Ä¢ {det['class']}: {det['confidence']:.3f} (obj: {det['obj_conf']:.3f})")
                    
                    # Save annotated frame
                    annotated = self.draw_detections(frame, detections)
                    output_path = self.output_dir / f"{video_name}_frame_{frame_idx:05d}.jpg"
                    cv2.imwrite(str(output_path), annotated)
                    
                    # Store detection info
                    results['detections'].append({
                        'frame': frame_idx,
                        'timestamp': frame_idx / fps if fps > 0 else 0,
                        'count': len(detections),
                        'details': detections
                    })
                
                # Progress
                if results['frames_processed'] % 10 == 0:
                    progress = (frame_idx / total_frames) * 100
                    print(f"   Progress: {progress:.1f}%")
            
            frame_idx += 1
        
        cap.release()
        
        print(f"   ‚úÖ Completed")
        print(f"   ‚Ä¢ Frames analyzed: {results['frames_processed']}")
        print(f"   ‚Ä¢ Total detections: {results['total_detections']}")
        if results['max_confidence'] > 0:
            print(f"   ‚Ä¢ Max confidence: {results['max_confidence']:.3f}")
        
        return results
    
    def test_all_videos(self):
        """Test all videos"""
        video_files = sorted(self.test_videos_dir.glob("*.mp4"))
        
        print("\n" + "="*60)
        print("üêÄ RODENT DETECTION TEST (FIXED)")
        print("="*60)
        print(f"Videos: {len(video_files)}")
        print(f"Threshold: {self.conf_threshold}")
        print(f"Output: {self.output_dir}")
        print("="*60)
        
        all_results = []
        total_detections = 0
        
        for video_file in video_files:
            result = self.process_video(video_file)
            if result:
                all_results.append(result)
                total_detections += result['total_detections']
        
        # Save results
        report = {
            'test_date': datetime.now().isoformat(),
            'total_videos': len(video_files),
            'total_detections': total_detections,
            'confidence_threshold': self.conf_threshold,
            'video_results': all_results
        }
        
        report_file = self.output_dir / "test_report.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        # Summary
        print("\n" + "="*60)
        print("TEST COMPLETE")
        print("="*60)
        
        if total_detections > 0:
            print(f"‚úÖ FOUND {total_detections} DETECTIONS!")
            print(f"\nDetections per video:")
            for r in all_results:
                if r['total_detections'] > 0:
                    print(f"   ‚Ä¢ {r['video']}: {r['total_detections']} detections (max conf: {r['max_confidence']:.3f})")
        else:
            print("‚ùå No detections found")
            print("\nDebugging info:")
            print("‚Ä¢ Model output shape correct: ‚úÖ")
            print("‚Ä¢ Inference running: ‚úÖ")
            print("‚Ä¢ Very low threshold used: ‚úÖ")
            print("\nLikely issues:")
            print("1. Model may not be trained for these specific videos")
            print("2. Videos might not contain clear rodent footage")
            print("3. Model might need retraining with similar footage")
        
        print(f"\nüìÅ Results saved to: {self.output_dir}")
        print("="*60)
        
        return total_detections > 0


def main():
    try:
        print("Starting fixed rodent detection test...")
        tester = FixedRodentTester()
        success = tester.test_all_videos()
        
        if success:
            print("\nüéâ SUCCESS! Rodents detected in videos!")
        else:
            print("\n‚ö†Ô∏è No detections - may need to check model training data")
            
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()